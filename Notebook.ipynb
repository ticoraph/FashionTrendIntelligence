{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## BIBLIOTHEQUES\n",
    "- `os` pour interagir avec le système de fichiers (lister les images).\n",
    "- `requests` pour effectuer des requêtes HTTP vers l'API.\n",
    "- `PIL (Pillow)` pour manipuler les images.\n",
    "- `matplotlib.pyplot` pour afficher les images et les masques.\n",
    "- `numpy` pour la manipulation des tableaux (les images sont des tableaux de pixels).\n",
    "- `tqdm.notebook` pour afficher une barre de progression (utile pour plusieurs images).\n",
    "- `base64` et `io` pour décoder les masques renvoyés par l'API."
   ],
   "id": "68433f2a7b2f6b6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from requests.adapters import HTTPAdapter\n",
    "from tqdm import tqdm\n",
    "import base64\n",
    "import io\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import time\n",
    "from urllib3 import Retry\n",
    "import cv2\n",
    "import shutil"
   ],
   "id": "ca74313370d1cfa7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## VARIABLES\n",
    "`CLASS_MAPPING`: Un dictionnaire qui associe les noms de classes (ex: \"Hat\") à des identifiants numériques.\n"
   ],
   "id": "23b86afc32c6e131"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "api_token = os.getenv('FASHION_TREND_INTELLIGENCE_TOKEN_READ')\n",
    "image_dir = \"IMG/\"\n",
    "list_of_image_paths = sorted(os.listdir(image_dir))\n",
    "print(list_of_image_paths)\n",
    "model_name = \"sayeed99/segformer_b3_clothes\"\n",
    "imgnocompliant = \"IMGNoCompliant/\"\n",
    "masknocompliant = \"MaskNoCompliant/\"\n",
    "\n",
    "CLASS_MAPPING = {\n",
    "    \"Background\": 0,\n",
    "    \"Hat\": 1,\n",
    "    \"Hair\": 2,\n",
    "    \"Sunglasses\": 3,\n",
    "    \"Upper-clothes\": 4,\n",
    "    \"Skirt\": 5,\n",
    "    \"Pants\": 6,\n",
    "    \"Dress\": 7,\n",
    "    \"Belt\": 8,\n",
    "    \"Left-shoe\": 9,\n",
    "    \"Right-shoe\": 10,\n",
    "    \"Face\": 11,\n",
    "    \"Left-leg\": 12,\n",
    "    \"Right-leg\": 13,\n",
    "    \"Left-arm\": 14,\n",
    "    \"Right-arm\": 15,\n",
    "    \"Bag\": 16,\n",
    "    \"Scarf\": 17\n",
    "}"
   ],
   "id": "aba7264b5dfad026",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## FONCTIONS\n",
    "1. `get_image_dimensions`: Récupérer les dimensions d'une image.\n",
    "2. `encode_image_to_base64`: Encoder une image en base64.\n",
    "3. `decode_base64_mask`: Décoder un masque de base64 en une image (tableau NumPy) et le redimensionner.\n",
    "4. `detect_content_type` : Recuperer le type de fichiers d'une image (png, jpeg, etc...)\n",
    "4.  `create_masks`: Combiner les masques de toutes les classes détectées en un seul masque de segmentation final, où chaque pixel a la valeur de l'ID de sa classe."
   ],
   "id": "3c4b3ae208495bcd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_image_dimensions(img_path):\n",
    "    \"\"\"\n",
    "    Get the dimensions of an image.\n",
    "    Args:\n",
    "        img_path (str): Path to the image.\n",
    "    Returns:\n",
    "        tuple: (width, height) of the image.\n",
    "    \"\"\"\n",
    "    original_image = Image.open(img_path)\n",
    "    return original_image.size\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Encode image to base64.\n",
    "    Args:\n",
    "        image_path (str): image.\n",
    "    Returns:\n",
    "        encoded_string: Base 67 encoded string.\n",
    "    \"\"\"\n",
    "    # Open the image file in binary read mode\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        # Read the file content, encode it to base64, and convert to UTF-8 string\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        # Return the base64 string with proper data URI format for JPEG images\n",
    "    return f\"data:image/png;base64,{encoded_string}\"\n",
    "\n",
    "def decode_base64_mask(base64_string, width, height):\n",
    "    \"\"\"\n",
    "    Decode a base64-encoded mask into a NumPy array.\n",
    "    Args:\n",
    "        base64_string (str): Base64-encoded mask.\n",
    "        width (int): Target width.\n",
    "        height (int): Target height.\n",
    "    Returns:\n",
    "        np.ndarray: Single-channel mask array.\n",
    "    \"\"\"\n",
    "    mask_data = base64.b64decode(base64_string)\n",
    "    mask_image = Image.open(io.BytesIO(mask_data))\n",
    "    mask_array = np.array(mask_image)\n",
    "    if len(mask_array.shape) == 3:\n",
    "        mask_array = mask_array[:, :, 0]  # Take first channel if RGB\n",
    "    mask_image = Image.fromarray(mask_array).resize((width, height), Image.NEAREST)\n",
    "    return np.array(mask_image)\n",
    "\n",
    "def detect_content_type(image_path_full):\n",
    "    \"\"\"\n",
    "    Detect Content type of image.\n",
    "    Args:\n",
    "        image_path_full (str): image path.\n",
    "    Returns:\n",
    "        format_to_mime: image format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path_full) as img:\n",
    "            format_to_mime = {\n",
    "                'JPEG': 'image/jpeg',\n",
    "                'PNG': 'image/png',\n",
    "                'GIF': 'image/gif',\n",
    "                'BMP': 'image/bmp',\n",
    "                'WEBP': 'image/webp',\n",
    "                'TIFF': 'image/tiff',\n",
    "                'ICO': 'image/x-icon',\n",
    "            }\n",
    "            return format_to_mime.get(img.format, f'image/{img.format.lower()}')\n",
    "    except Exception as e:\n",
    "        print(f\"Error {e}\")\n",
    "        return None\n",
    "\n",
    "def create_masks(results, width, height):\n",
    "    \"\"\"\n",
    "    Combine multiple class masks into a single segmentation mask.\n",
    "    Args:\n",
    "        results (list): List of dictionaries with 'label' and 'mask' keys.\n",
    "        width (int): Target width.\n",
    "        height (int): Target height.\n",
    "    Returns:\n",
    "        np.ndarray: Combined segmentation mask with class indices.\n",
    "    \"\"\"\n",
    "    combined_mask = np.zeros((height, width), dtype=np.uint8)  # Initialize with Background (0)\n",
    "\n",
    "    # Process non-Background masks first\n",
    "    for result in results:\n",
    "        label = result['label']\n",
    "        class_id = CLASS_MAPPING.get(label, 0)\n",
    "        if class_id == 0:  # Skip Background\n",
    "            continue\n",
    "        mask_array = decode_base64_mask(result['mask'], width, height)\n",
    "        combined_mask[mask_array > 0] = class_id\n",
    "\n",
    "    # Process Background last to ensure it doesn't overwrite other classes unnecessarily\n",
    "    # (Though the model usually provides non-overlapping masks for distinct classes other than background)\n",
    "    for result in results:\n",
    "        if result['label'] == 'Background':\n",
    "            mask_array = decode_base64_mask(result['mask'], width, height)\n",
    "            # Apply background only where no other class has been assigned yet\n",
    "            # This logic might need adjustment based on how the model defines 'Background'\n",
    "            # For this model, it seems safer to just let non-background overwrite it first.\n",
    "            # A simple application like this should be fine: if Background mask says pixel is BG, set it to 0.\n",
    "            # However, a more robust way might be to only set to background if combined_mask is still 0 (initial value)\n",
    "            combined_mask[mask_array > 0] = 0 # Class ID for Background is 0\n",
    "\n",
    "    return combined_mask"
   ],
   "id": "3dc49c3e8b7bd96a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SEGMENTATION",
   "id": "60d43a59c7611d11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def segment_images_batch(list_of_image_paths):\n",
    "    \"\"\"\n",
    "    Segmente une liste d'images en utilisant l'API Hugging Face.\n",
    "    Args:\n",
    "        list_of_image_paths (list): Liste des chemins vers les images.\n",
    "    Returns:\n",
    "        list: Liste des masques de segmentation (tableaux NumPy).\n",
    "              Contient None si une image n'a pas pu être traitée.\n",
    "    \"\"\"\n",
    "    batch_segmentations = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for image_path in tqdm(list_of_image_paths,desc=\"Segmentation\",unit=\"image\",colour=\"green\"):\n",
    "        try:\n",
    "            image_path_full = image_dir + image_path\n",
    "\n",
    "            # Image Dimensions\n",
    "            image_dimensions = get_image_dimensions(image_path_full)\n",
    "            # Content Type\n",
    "            content_type = detect_content_type(image_path_full)\n",
    "\n",
    "            if content_type == \"image/png\" and image_dimensions == (400, 600):\n",
    "\n",
    "                print(f\"Traitement: {image_path}\")\n",
    "\n",
    "                ############### API Request ################\n",
    "                api_url = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
    "                headers = {\n",
    "                    \"Authorization\": f\"Bearer {api_token}\",\n",
    "                    \"Content-Type\": \"application/json\"\n",
    "                }\n",
    "                base64_image = encode_image_to_base64(image_path_full)\n",
    "                payload = {\"inputs\": base64_image}\n",
    "\n",
    "                try:\n",
    "                    response = requests.post(api_url, headers=headers, json=payload, timeout=30)\n",
    "                    response.raise_for_status()\n",
    "                    print(f\" HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "                    # Store response data\n",
    "                    response_data = response.json()\n",
    "\n",
    "                    # Create Mask\n",
    "                    combined_mask = create_masks(response_data, image_dimensions[0], image_dimensions[1])\n",
    "                    # Append List\n",
    "                    batch_segmentations.append(combined_mask)\n",
    "\n",
    "                except requests.exceptions.HTTPError as http_err:\n",
    "                    print(f\"HTTP error occurred for {image_path}: {http_err}\")\n",
    "                    batch_segmentations.append(None)\n",
    "\n",
    "                except requests.exceptions.Timeout:\n",
    "                    print(f\"Timeout error for {image_path}\")\n",
    "                    batch_segmentations.append(None)\n",
    "\n",
    "                except requests.exceptions.RequestException as req_err:\n",
    "                    print(f\"Request error for {image_path}: {req_err}\")\n",
    "                    batch_segmentations.append(None)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during API request {image_path}: {e}\")\n",
    "                    batch_segmentations.append(None)\n",
    "\n",
    "            else:\n",
    "                print(f\"Image {image_path} ne correspond pas aux critères (PNG 400x600)\")\n",
    "                try:\n",
    "\n",
    "                    imgnocompliant_destination = os.path.join(imgnocompliant, os.path.basename(image_path))\n",
    "                    shutil.move(image_path_full, imgnocompliant_destination)\n",
    "\n",
    "                    # Mask/mask_0.png  MaskNoCompliant/mask_0.png\n",
    "                    numero = (image_path.split(\"_\")[1]).split(\".\")[0]\n",
    "                    masknocompliant_source = \"Mask/mask_\" + numero +\".png\"\n",
    "                    masknocompliant_destination = \"MaskNoCompliant/mask_\" + numero +\".png\"\n",
    "                    shutil.move(masknocompliant_source, masknocompliant_destination)\n",
    "                    print(f\"  -> Image déplacée vers: {imgnocompliant_destination} et {masknocompliant_destination}\")\n",
    "                except Exception as move_err:\n",
    "                    print(f\"  -> Erreur lors du déplacement de {image_path}: {move_err}\")\n",
    "\n",
    "                batch_segmentations.append(None)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du traitement de {image_path}: {e}\")\n",
    "            batch_segmentations.append(None)\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return batch_segmentations\n",
    "\n",
    "# Appeler la fonction pour segmenter les images listées dans image_paths\n",
    "if list_of_image_paths:\n",
    "    print(f\"\\nTraitement de {len(list_of_image_paths)} image(s) en batch...\")\n",
    "    batch_seg_results = segment_images_batch(list_of_image_paths)\n",
    "    print(\"Traitement en batch terminé.\")\n",
    "    print(f\"Résultats: {len([x for x in batch_seg_results if x is not None])} images traitées avec succès\")\n",
    "else:\n",
    "    batch_seg_results = []\n",
    "    print(\"Aucune image à traiter en batch.\")"
   ],
   "id": "812405dd6e14ae99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RESULTATS",
   "id": "9b4e20d57e2bae3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Nombre total de résultats: {len(batch_seg_results)}\")\n",
    "list_of_image_paths = sorted(os.listdir(image_dir))\n",
    "\n",
    "def display_segmented_images_batch(list_of_image_paths, segmentation_masks):\n",
    "    \"\"\"\n",
    "    Affiche les images originales et leurs masques segmentés.\n",
    "    Args:\n",
    "        original_image_paths (list): Liste des chemins des images originales.\n",
    "        segmentation_masks (list): Liste des masques segmentés (NumPy arrays).\n",
    "    \"\"\"\n",
    "\n",
    "    for image_path, segmentation_mask in zip(list_of_image_paths, segmentation_masks):\n",
    "        print(image_path)\n",
    "        #print(segmentation_mask)\n",
    "        image_open = Image.open(image_dir + image_path)\n",
    "\n",
    "        # Premier sous-graphique\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image_open)\n",
    "        plt.title('Image Original')\n",
    "        plt.axis('off')\n",
    "\n",
    "        if  segmentation_mask is not None :\n",
    "            # Deuxième sous-graphique\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(segmentation_mask, cmap='tab10', interpolation='nearest')\n",
    "            plt.title('Masque Predit')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            numero = (image_path.split(\"_\")[1]).split(\".\")[0]\n",
    "            # Sauvegarde du masque dans les dossiers appropriés\n",
    "            cv2.imwrite(os.path.join(\"MaskPrediction\", f\"mask_{numero}.png\"), segmentation_mask)\n",
    "\n",
    "# Afficher les résultats du batch\n",
    "if batch_seg_results:\n",
    "    display_segmented_images_batch(list_of_image_paths, batch_seg_results)\n",
    "else:\n",
    "    print(\"Aucun résultat de segmentation à afficher.\")"
   ],
   "id": "1beaf950cdf80b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RESULTATS\n",
   "id": "eab83d33067278b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder_img = \"IMG/\"\n",
    "folder_mask_true = \"Mask/\"\n",
    "folder_mask_pred = \"MaskPrediction/\"\n",
    "folder_concatenated = \"IMGConcat/\"\n",
    "\n",
    "# 2. Définition d'un colormap personnalisé et lecture des paires\n",
    "# Colormap personnalisé pour 4 classes (valeurs 1 à 4) en BGR\n",
    "custom_colormap = {\n",
    "    1: (0, 255, 255),  # Jaune - Hat\n",
    "    2: (0, 165, 255),  # Orange - Hair\n",
    "    3: (255, 0, 255),  # Magenta - Sunglasses\n",
    "    4: (0, 0, 255),  # Rouge - Upper-clothes\n",
    "    5: (255, 255, 0),  # Cyan - Skirt\n",
    "    6: (0, 255, 0),  # Vert - Pants\n",
    "    7: (255, 0, 0),  # Bleu - Dress\n",
    "    8: (128, 0, 128),  # Violet - Belt\n",
    "    9: (0, 255, 255),  # Jaune - Left-shoe\n",
    "    10: (255, 140, 0),  # Orange foncé - Right-shoe\n",
    "    11: (200, 180, 140),  # Beige - Face\n",
    "    12: (200, 180, 140),  # Beige - Left-leg\n",
    "    13: (200, 180, 140),  # Beige - Right-leg\n",
    "    14: (200, 180, 140),  # Beige - Left-arm\n",
    "    15: (200, 180, 140),  # Beige - Right-arm\n",
    "    16: (0, 128, 255),  # Bleu clair - Bag\n",
    "    17: (255, 20, 147)  # Rose - Scarf\n",
    "}\n",
    "\n",
    "# Légendes associées aux labels\n",
    "legend_labels = {\n",
    "    \"0\": \"Background\",\n",
    "    \"1\": \"Hat\",\n",
    "    \"2\": \"Hair\",\n",
    "    \"3\": \"Sunglasses\",\n",
    "    \"4\": \"Upper-clothes\",\n",
    "    \"5\": \"Skirt\",\n",
    "    \"6\": \"Pants\",\n",
    "    \"7\": \"Dress\",\n",
    "    \"8\": \"Belt\",\n",
    "    \"9\": \"Left-shoe\",\n",
    "    \"10\": \"Right-shoe\",\n",
    "    \"11\": \"Face\",\n",
    "    \"12\": \"Left-leg\",\n",
    "    \"13\": \"Right-leg\",\n",
    "    \"14\": \"Left-arm\",\n",
    "    \"15\": \"Right-arm\",\n",
    "    \"16\": \"Bag\",\n",
    "    \"17\": \"Scarf\"\n",
    "}\n",
    "\n",
    "# Lecture des paires image/mask depuis les dossiers\n",
    "list_img = sorted(os.listdir(folder_img))\n",
    "list_mask_true = sorted(os.listdir(folder_mask_true))\n",
    "list_mask_pred = sorted(os.listdir(folder_mask_pred))\n",
    "\n",
    "datas = []\n",
    "for img, mask_true, mask_pred in zip(list_img, list_mask_true, list_mask_pred):\n",
    "    img = os.path.join(folder_img, img)\n",
    "    mask_true = os.path.join(folder_mask_true, mask_true)\n",
    "    mask_pred = os.path.join(folder_mask_pred, mask_pred)\n",
    "\n",
    "    idx = (img.split(\"_\")[1]).split(\".\")[0]\n",
    "\n",
    "    img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    mask_true = cv2.imread(mask_true, cv2.IMREAD_GRAYSCALE)\n",
    "    mask_pred = cv2.imread(mask_pred, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    new_data = {\n",
    "        'img': img,\n",
    "        'mask_true': mask_true,\n",
    "        'mask_pred': mask_pred,\n",
    "        'idx': idx,\n",
    "    }\n",
    "    datas.append(new_data)\n",
    "\n",
    "print(\"Lecture des paires image/mask effectuée.\")\n",
    "print(datas[2])\n",
    "\n",
    "# 3. Fonctions pour coloriser le masque et ajouter la légende\n",
    "def colorize_mask(mask, colormap):\n",
    "    \"\"\"\n",
    "    Applique le colormap personnalisé au masque.\n",
    "    Pour chaque pixel, s'il correspond à un label défini dans colormap,\n",
    "    la couleur correspondante est assignée.\n",
    "    \"\"\"\n",
    "    colored_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "    for label, color in colormap.items():\n",
    "        colored_mask[mask == label] = color\n",
    "    return colored_mask\n",
    "\n",
    "\n",
    "def add_legend(image, legend, start_x=10, start_y=10, box_size=15, spacing=5):\n",
    "    \"\"\"\n",
    "    Ajoute une légende sur l'image.\n",
    "    Pour chaque label, dessine un rectangle de la couleur correspondante et le texte associé.\n",
    "    \"\"\"\n",
    "    img_with_legend = image.copy()\n",
    "    y = start_y\n",
    "    for label, text in legend.items():\n",
    "        # Récupération de la couleur du label\n",
    "        color = custom_colormap.get(int(label), (255, 255, 255))\n",
    "        # Dessin d'un petit rectangle rempli\n",
    "        cv2.rectangle(img_with_legend, (start_x, y), (start_x + box_size, y + box_size), color, -1)\n",
    "        # Ajout du texte à droite du rectangle\n",
    "        cv2.putText(img_with_legend, text, (start_x + box_size + spacing, y + box_size - 2),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        y += box_size + spacing\n",
    "    return img_with_legend\n",
    "\n",
    "\n",
    "print(f\"Nombre d'images à traiter: {len(datas)}\")\n",
    "print(f\"Exemple de données chargées:\")\n",
    "print(f\"  Index: {datas[0]['idx']}\")\n",
    "print(f\"  Image shape: {datas[0]['img'].shape}\")\n",
    "print(f\"  Mask true shape: {datas[0]['mask_true'].shape}\")\n",
    "print(f\"  Mask pred shape: {datas[0]['mask_pred'].shape}\")\n",
    "\n",
    "# 4. Application du colormap, ajout de la légende et superposition image/mask\n",
    "for data in datas:\n",
    "    img = data['img']\n",
    "    mask_true = data['mask_true']\n",
    "    mask_pred = data['mask_pred']\n",
    "    idx = data['idx']\n",
    "\n",
    "    # Colorisation du masque avec le colormap personnalisé\n",
    "    colored_mask_true = colorize_mask(mask_true, custom_colormap)\n",
    "    colored_mask_pred = colorize_mask(mask_pred, custom_colormap)\n",
    "\n",
    "    # Ajout de la légende sur le masque colorisé\n",
    "    colored_mask_pred_with_legend = add_legend(colored_mask_pred, legend_labels)\n",
    "\n",
    "    # Superposition du masque coloré sur l'image originale\n",
    "    overlay = cv2.addWeighted(img, 0.7, colored_mask_pred, 0.3, 0)\n",
    "    overlay_with_legend = add_legend(overlay, legend_labels)\n",
    "\n",
    "    # Concatenation des images sur une seule ligne\n",
    "    concatenated = np.hstack([img, colored_mask_true, colored_mask_pred_with_legend, overlay])\n",
    "\n",
    "    # Affichage des résultats dans Colab\n",
    "    print(f\"Résultat {idx} :\")\n",
    "\n",
    "    cv2.imwrite(f\"{folder_concatenated}/concat_{idx}.png\", concatenated)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.imshow(cv2.cvtColor(concatenated, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Paire {idx}\")\n",
    "    plt.show()\n"
   ],
   "id": "490228ce23865421",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a1a516c791f6345d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
